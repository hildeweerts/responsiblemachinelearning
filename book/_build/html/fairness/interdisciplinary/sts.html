
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Science and Technology Studies: Abstraction Traps &#8212; An Introduction to Responsible Machine Learning</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Tutorials" href="../tutorials/introduction.html" />
    <link rel="prev" title="Law: Fairness and Discrimination" href="law.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">An Introduction to Responsible Machine Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../index.html">
                    An Introduction to Responsible Machine Learning
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../introduction/introduction.html">
   Responsible Machine Learning
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../introduction/machinelearning/introduction.html">
   Machine Learning Preliminaries
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../introduction/machinelearning/modelevaluation.html">
     Model Evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../introduction/machinelearning/modelselection.html">
     Model Selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../introduction/machinelearning/costsensitivelearning.html">
     Cost-Sensitive Learning
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Fairness
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../introduction.html">
   Algorithmic Fairness
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../groupfairnessmetrics.html">
   Group Fairness Metrics
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../fairml/introduction.html">
   Fairness-Aware Machine Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../fairml/preprocessing.html">
     Pre-processing Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../fairml/constrainedlearning.html">
     Constrained Learning Algorithms
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../fairml/postprocessing.html">
     Post-processing Algorithms
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="introduction.html">
   Interdisciplinary Perspectives on Fair-ML
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="philosophy.html">
     Philosophy: What is “Fair”?
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="law.html">
     Law: Fairness and Discrimination
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Science and Technology Studies: Abstraction Traps
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../tutorials/introduction.html">
   Tutorials
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../tutorials/measuringgroupfairness.html">
     Measuring Group Fairness
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../tutorials/fairnessawareclassification.html">
     Fairness-Aware Classification
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Misc
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../misc/harms.html">
   List of Harms
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/hildeweerts/responsiblemachinelearning"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/hildeweerts/responsiblemachinelearning/issues/new?title=Issue%20on%20page%20%2Ffairness/interdisciplinary/sts.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/fairness/interdisciplinary/sts.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-framing-trap">
   The Framing Trap
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-portability-trap">
   The Portability Trap
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-formalism-trap">
   The Formalism Trap
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-ripple-effect-trap">
   The Ripple Effect Trap
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-solutionism-trap">
   The Solutionism Trap
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#concluding-remarks">
   Concluding Remarks
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Science and Technology Studies: Abstraction Traps</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-framing-trap">
   The Framing Trap
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-portability-trap">
   The Portability Trap
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-formalism-trap">
   The Formalism Trap
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-ripple-effect-trap">
   The Ripple Effect Trap
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-solutionism-trap">
   The Solutionism Trap
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#concluding-remarks">
   Concluding Remarks
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="science-and-technology-studies-abstraction-traps">
<span id="abstraction-traps"></span><h1>Science and Technology Studies: Abstraction Traps<a class="headerlink" href="#science-and-technology-studies-abstraction-traps" title="Permalink to this headline">#</a></h1>
<p>Translating a real-world problem into a machine learning task is not easy. By definition, a model is a simplification of reality. A data scientist’s task is to decide which elements of the real world need to be included in the model and which elements will be left out of scope. To this end, some amount of abstraction is required. This involves removing details to focus attention on general patterns. The impact of your system, both positive and negative, highly depends on how you define the machine learning task. By abstracting away the context surrounding a model and its inputs and outputs, you may accidentally abstract away some of the consequences as well – leaving them unaccounted for. A mismatch between the machine learning task and the real-world context is referred to as an abstraction trap <a class="footnote-reference brackets" href="#footcite-selbst2019" id="id1">1</a>.</p>
<section id="the-framing-trap">
<h2>The Framing Trap<a class="headerlink" href="#the-framing-trap" title="Permalink to this headline">#</a></h2>
<p>Machine learning models hardly ever operate in isolation. A decision-making process may incorporate (multiple) other machine learning models or human decision-makers. The framing trap considers the failure to model the relevant aspects of the larger system your machine learning model is a part of.</p>
<p>For example, consider a scenario in which judges need to decide whether a defendant is detained. To assist them in their decision-making process, they may be provided with a machine learning model that predicts the risk of recidivism; i.e., the risk that the defendant will re-offend. Notably, the final decision of the judge determines the real-world consequences, not the model’s prediction. Hence, if fairness is a requirement, it is not sufficient to consider the output of the model; you also need to consider how the predictions are used by the judges.</p>
<p>In many real-world systems, several machine learning models are deployed at the same time at different points in the decision-making process. Unfortunately, a system of components that seem fair in isolation does not automatically imply a fair system, i.e. \textit{Fair + Fair <span class="math notranslate nohighlight">\(\neq\)</span> Fair} <a class="footnote-reference brackets" href="#footcite-dwork2020" id="id2">2</a>.</p>
<p>To avoid the framing trap, we need to ensure that the way we frame our problem and evaluate our solution includes all relevant components and actors of the sociotechnical system.</p>
</section>
<section id="the-portability-trap">
<h2>The Portability Trap<a class="headerlink" href="#the-portability-trap" title="Permalink to this headline">#</a></h2>
<p>A system that is carefully designed for a particular context cannot always be directly applied in a different context. Taking an existing solution and applying it in a different situation without taking into account the differences between the two contexts is known as the portability trap. A shift in domain, geographical location, time, or even the nature of the decision-making process all impact the suitability of a system. For example, a voice recognition system optimized for speakers with an Australian accent may fail horribly when deployed in the United States. Similarly, the expectations of a good manager have changed considerably in the past few decades, including a stronger need for soft skills. A model trained on annual reviews in the 1960s will likely not be suitable to make predictions for current managers. The portability trap goes beyond performance issues due to differences in the data distribution. It also considers differences in social norms and actors. For example, a chatbot optimized to formulate snarky replies may be considered funny on a gaming platform, but inappropriate or even offensive in a more formal context, such as a website for loan applications. To avoid falling into the portability trap, we need to consider whether our problem understanding adequately models the social and technical requirements of the actual deployment context.</p>
</section>
<section id="the-formalism-trap">
<h2>The Formalism Trap<a class="headerlink" href="#the-formalism-trap" title="Permalink to this headline">#</a></h2>
<p>In order to use machine learning, you need to formulate your problem in a way that a mathematical algorithm can understand. This is not a straightforward task: there are usually many different ways to measure something. Some may be more appropriate than others. You fall into the formalism trap when your formalization does not adequately take into account the context in which your model will be used. For example, machine learning problem formulations often simplify the decision space to a very limited set of actions <a class="footnote-reference brackets" href="#footcite-mitchell2018" id="id3">3</a>. In lending, the decision space of the machine learning model may consist of two options: reject or accept. In reality, there may be many more actions available, such as recommending a different type of loan.</p>
<p>The formalism trap is closely related to the statistical concept of construct validity: how well does the formalization measure the construct of interest? Business objectives often involve constructs such as “employee quality” or “creditworthiness” that cannot be measured directly <a class="footnote-reference brackets" href="#footcite-jacobs2019" id="id4">4</a>. In such cases, data scientists may use a proxy variable instead. Every variable in a data set is the result of a decision on how a particular construct can be measured on a computer-readable scale. For example, Netflix has chosen to measure viewers’ quality judgments with likes, rather than the more commonly used 1 - 5 star rating <a class="footnote-reference brackets" href="#footcite-dobbe2018" id="id5">5</a>.</p>
<p>Not all variables measure the intended construct equally well. For example, income measures the construct socioeconomic status to some degree but does not capture other factors such as wealth and education <a class="footnote-reference brackets" href="#footcite-jacobs2019" id="id6">4</a>. A mismatch between the choice of target variable and the actual construct of interest can be detrimental to fairness goals. In particular, fairness concerns can arise when the measurement error introduced by the choice of formalization differs across groups. For example, you may be interested in predicting crime, but only have access to a subset of all criminal activity: arrest records. In societies where arrest records are the result of racially biased policing practices, the measurement error will differ across racial groups. Similarly, Obermeyer <em>et al.</em><a class="footnote-reference brackets" href="#footcite-obermeyer2019" id="id7">6</a> found that due to unequal access to healthcare, historically less money has been spent on caring for African-American patients compared to Caucasian patients. Consequently, a system that used healthcare costs as a proxy for true healthcare needs systematically underestimated the needs of African-American patients.</p>
<p>Issues of construct validity are especially complex for social constructs such as race and gender. Almost paradoxically, measuring sensitive characteristics can introduce bias. In industry and academia, it is common to “infer” these characteristics from observed data, such as facial analysis <a class="footnote-reference brackets" href="#footcite-jacobs2019" id="id8">4</a>. This can be problematic because such approaches often fail to acknowledge that social constructs are inherently contextual, may change over time, and are multidimensional. For example, when talking about race, one may be referring to somebody’s racial identity (i.e., self-identified race), their observed race (i.e., the race others believe them to be), their phenotype (i.e., racial appearance), or even their reflected race (i.e., the race they believe others assume them to be). Which dimension you measure will influence the conclusions you can draw (see Hanna <em>et al.</em><a class="footnote-reference brackets" href="#footcite-hanna2020" id="id9">7</a> for a more detailed account).</p>
<p>To avoid falling into the formalism trap, data scientists should take into account whether the problem formulation handles (social) constructs in a way that matches the intended deployment context. To mitigate threats to construct validity, ideally, multiple measures are collected, especially for complex constructs.</p>
</section>
<section id="the-ripple-effect-trap">
<h2>The Ripple Effect Trap<a class="headerlink" href="#the-ripple-effect-trap" title="Permalink to this headline">#</a></h2>
<p>Introducing a machine learning model in a social context may affect the behavior of other actors in the system and, as a result, the context itself. This is known as the ripple effect trap. There are several ways in which a social context may change due to the introduction of new technology. First, the introduction of a new technology might be used to argue for or reinforce power, which can change an organization’s dynamics. For example, management may purchase software for monitoring workers, reinforcing the power relationship between management and subordinates. Second, the introduction of a prediction system may cause reactivity behavior. For example, people might attempt to game an automated loan approval system by dishonestly filling out their data in the hope of a more favorable outcome. Third, a system that was developed for a particular use case, may be used in unintended, perhaps even adversarial, ways. To avoid falling into the ripple effect trap, it is important to consider whether the envisioned system predictably changes the context.</p>
</section>
<section id="the-solutionism-trap">
<h2>The Solutionism Trap<a class="headerlink" href="#the-solutionism-trap" title="Permalink to this headline">#</a></h2>
<p>The possible benefits that machine learning solutions can bring can be very exciting. Unfortunately, machine learning is not the answer to everything (\textit{what?!}). The belief that every problem has a technological solution is referred to as solutionism. We fall into the solutionism trap when we fail to recognize machine learning is not the right tool for the problem at hand.</p>
<p>The solutionism trap is closely related to the optimism bias. This is a cognitive bias that causes people to overestimate the likelihood of positive events and underestimate the likelihood of negative events. In the context of algorithmic systems, optimism bias occurs when policymakers or developers are overly optimistic about a system’s benefits while underestimating its limitations and weaknesses. In particular, people might overestimate the objectiveness of data and algorithmic systems. If this happens, the system’s goals, development, and outcomes might not be sufficiently scrutinized, which can result in systematic harm.</p>
<p>There are several reasons why machine learning may not be the right tool to solve a problem. In some scenarios, it may not be possible to adequately model the context using automated data collection. For example, consider eligibility for social welfare benefits in the Netherlands. Although the criteria for eligibility are set in the law, some variables, e.g. living situation, are difficult to measure quantitatively. Moreover, the Dutch legal system contains the possibility to deviate from the criteria due to compelling personal circumstances. It is impossible to anticipate all context-dependent situations in advance. As a result, machine learning may not be the best tool for this job. In other scenarios, machine learning may be inappropriate because it lacks human connection. For example, consider a person who is hospitalized. In theory, it may be possible to develop a robot nurse who is perfectly capable of performing tasks such as inserting an IV or washing the patient. However, the patient may also value the genuine interest and concern of a nurse – in other words, a human connection, something a machine learning model cannot (or even should not) provide. Furthermore, there may be cases where machine learning is simply overkill. For example, you may wonder whether spending several months on optimizing a deep learning computer vision system to predict the dimensions of items in your online shop is a better approach than simply asking the person who puts the item on the website to fill out the dimensions.</p>
<p>To avoid falling into the solutionism trap`, it is useful to consider machine learning as a means to an end. In other words, rather than asking “can we use machine learning”, ask, “how can we solve this problem?” and then consider machine learning as one of the options.</p>
</section>
<section id="concluding-remarks">
<h2>Concluding Remarks<a class="headerlink" href="#concluding-remarks" title="Permalink to this headline">#</a></h2>
<p>Understanding, flagging, and avoiding abstraction traps are an important step towards machine learning systems that are not only fair in theory, but also in practice.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>When considering designing a new (fair-)ML solution, determine…</p>
<ol class="simple">
<li><p>Whether machine learning is the right tool for this problem in the first place (<em>solutionism trap</em>).</p></li>
<li><p>The possible unintended consequences of introducing a machine learning model in the existing
sociotechnical sytstem (<em>ripple effect trap</em>)</p></li>
<li><p>Whether the way you quantify variables and metrics makes sense (<em>formalism trap</em>)</p></li>
<li><p>Whether the requirements reflect the actual deployment context (<em>portability trap</em>)</p></li>
<li><p>Whether you have included all the relevant parts of the sociotechnical system in your model and
evaluation (<em>framing trap</em>)</p></li>
</ol>
</div>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">#</a></h2>
<div class="docutils container" id="id10">
<dl class="footnote brackets">
<dt class="label" id="footcite-selbst2019"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Andrew D. Selbst, Danah Boyd, Sorelle A. Friedler, Suresh Venkatasubramanian, and Janet Vertesi. Fairness and abstraction in sociotechnical systems. <em>FAT* 2019 - Proceedings of the 2019 Conference on Fairness, Accountability, and Transparency</em>, pages 59–68, 2019. <a class="reference external" href="https://doi.org/10.1145/3287560.3287598">doi:10.1145/3287560.3287598</a>.</p>
</dd>
<dt class="label" id="footcite-dwork2020"><span class="brackets"><a class="fn-backref" href="#id2">2</a></span></dt>
<dd><p>Cynthia Dwork, Christina Ilvento, and Meena Jagadeesan. Individual fairness in pipelines. <em>arXiv preprint arXiv:2004.05167</em>, 2020.</p>
</dd>
<dt class="label" id="footcite-mitchell2018"><span class="brackets"><a class="fn-backref" href="#id3">3</a></span></dt>
<dd><p>Shira Mitchell, Eric Potash, Solon Barocas, Alexander D’Amour, and Kristian Lum. Prediction-based decisions and fairness: a catalogue of choices, assumptions, and definitions. 2018. <a class="reference external" href="https://arxiv.org/abs/1811.07867">arXiv:1811.07867</a>.</p>
</dd>
<dt class="label" id="footcite-jacobs2019"><span class="brackets">4</span><span class="fn-backref">(<a href="#id4">1</a>,<a href="#id6">2</a>,<a href="#id8">3</a>)</span></dt>
<dd><p>Abigail Z. Jacobs and Hanna Wallach. Measurement and fairness. In <em>Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</em>, FAccT ‘21, 375–385. New York, NY, USA, 2021. Association for Computing Machinery. URL: <a class="reference external" href="https://doi.org/10.1145/3442188.3445901">https://doi.org/10.1145/3442188.3445901</a>, <a class="reference external" href="https://doi.org/10.1145/3442188.3445901">doi:10.1145/3442188.3445901</a>.</p>
</dd>
<dt class="label" id="footcite-dobbe2018"><span class="brackets"><a class="fn-backref" href="#id5">5</a></span></dt>
<dd><p>Roel Dobbe, Sarah Dean, Thomas Gilbert, and Nitin Kohli. A broader view on bias in automated decision-making: reflecting on epistemology and dynamics. <em>arXiv preprint arXiv:1807.00553</em>, 2018.</p>
</dd>
<dt class="label" id="footcite-obermeyer2019"><span class="brackets"><a class="fn-backref" href="#id7">6</a></span></dt>
<dd><p>Ziad Obermeyer, Brian Powers, Christine Vogeli, and Sendhil Mullainathan. Dissecting racial bias in an algorithm used to manage the health of populations. <em>Science</em>, 366(6464):447–453, 2019. URL: <a class="reference external" href="https://science.sciencemag.org/content/366/6464/447">https://science.sciencemag.org/content/366/6464/447</a>, <a class="reference external" href="https://arxiv.org/abs/https://science.sciencemag.org/content/366/6464/447.full.pdf">arXiv:https://science.sciencemag.org/content/366/6464/447.full.pdf</a>, <a class="reference external" href="https://doi.org/10.1126/science.aax2342">doi:10.1126/science.aax2342</a>.</p>
</dd>
<dt class="label" id="footcite-hanna2020"><span class="brackets"><a class="fn-backref" href="#id9">7</a></span></dt>
<dd><p>Alex Hanna, Emily Denton, Andrew Smart, and Jamila Smith-Loud. Towards a critical race methodology in algorithmic fairness. In <em>FAT* 2020 - Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency</em>, 501–512. dec 2020. URL: <a class="reference external" href="https://arxiv.org/abs/1912.03593">https://arxiv.org/abs/1912.03593</a>, <a class="reference external" href="https://arxiv.org/abs/1912.03593">arXiv:1912.03593</a>, <a class="reference external" href="https://doi.org/10.1145/3351095.3372826">doi:10.1145/3351095.3372826</a>.</p>
</dd>
</dl>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./fairness/interdisciplinary"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="law.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Law: Fairness and Discrimination</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../tutorials/introduction.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Tutorials</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Hilde Weerts<br/>
  
      &copy; Copyright 2024.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>