
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Responsible Machine Learning &#8212; An Introduction to Responsible Machine Learning</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Machine Learning Preliminaries" href="machinelearning/introduction.html" />
    <link rel="prev" title="An Introduction to Responsible Machine Learning" href="../index.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
      
      
      <h1 class="site-logo" id="site-title">An Introduction to Responsible Machine Learning</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    An Introduction to Responsible Machine Learning
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Responsible Machine Learning
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="machinelearning/introduction.html">
   Machine Learning Preliminaries
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="machinelearning/modelevaluation.html">
     Model Evaluation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="machinelearning/modelselection.html">
     Model Selection
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="machinelearning/costsensitivelearning.html">
     Cost-Sensitive Learning
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Fairness
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../fairness/introduction.html">
   Algorithmic Fairness
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../fairness/groupfairness/introduction.html">
   Measuring Fairness
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../fairness/groupfairness/biases.html">
     Biases as Sources of Unfairness
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../fairness/groupfairness/groupfairnessmetrics.html">
     Group Fairness Metrics
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../fairness/groupfairness/normativeunderpinnings.html">
     Choosing the “Right” Fairness Metric
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../fairness/fairml/introduction.html">
   Fairness-Aware Machine Learning
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../fairness/fairml/nofairnessthroughunawareness.html">
     No Fairness through Unawareness
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../fairness/fairml/groupspecificthresholds.html">
     Group-Specific Decision Thresholds
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Explainability
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../explainability/introduction.html">
   Explainable Machine Learning
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../explainability/localposthoc/introduction.html">
   Local Post-Hoc Explanations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../explainability/localposthoc/lime.html">
     LIME
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../explainability/localposthoc/shap.html">
     SHAP
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../explainability/localposthoc/discussion.html">
     Feature importance
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../explainability/globalposthoc/introduction.html">
   Global Post-Hoc Explanations
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../explainability/globalposthoc/pdp.html">
     Partial Dependence Plots
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Misc
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../misc/harms.html">
   List of Harms
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../misc/glossary.html">
   Glossary
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/hildeweerts/responsiblemachinelearning"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/hildeweerts/responsiblemachinelearning/issues/new?title=Issue%20on%20page%20%2Fintroduction/introduction.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/introduction/introduction.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-do-i-mean-by-responsible-machine-learning">
   What do I mean by
   <em>
    Responsible Machine Learning
   </em>
   ?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fairness">
     Fairness
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#transparency">
     Transparency
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#for-who-is-this-book">
   For who is this book?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-covered-in-this-book">
   What is covered in this book?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#navigating-this-book">
   Navigating this book
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Responsible Machine Learning</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-do-i-mean-by-responsible-machine-learning">
   What do I mean by
   <em>
    Responsible Machine Learning
   </em>
   ?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#fairness">
     Fairness
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#transparency">
     Transparency
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#for-who-is-this-book">
   For who is this book?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#what-is-covered-in-this-book">
   What is covered in this book?
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#navigating-this-book">
   Navigating this book
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="responsible-machine-learning">
<span id="introduction"></span><h1>Responsible Machine Learning<a class="headerlink" href="#responsible-machine-learning" title="Permalink to this headline">#</a></h1>
<p>With the advent of large-scale data collection, the toolkit of a data scientist has proven to be a powerful way to make products and processes faster, cheaper, and better. Many data science applications make use of <a class="reference internal" href="../misc/glossary.html#term-machine-learning"><span class="xref std std-term">machine learning</span></a> algorithms: algorithms that build mathematical models by ‘learning’ from data. Nowadays, machine learning models are integrated in many computer systems: from music recommendations to automated fraud detection, facial recognition systems, and personalized medicine assistants. These systems can provide benefits, but are not without risks.</p>
<p>A responsible data scientist understands how machine learning models might be harmful and how the risks can be mitigated. This online book provides a practical introduction to the nascent field of responsible machine learning.</p>
<div class="section" id="what-do-i-mean-by-responsible-machine-learning">
<h2>What do I mean by <em>Responsible Machine Learning</em>?<a class="headerlink" href="#what-do-i-mean-by-responsible-machine-learning" title="Permalink to this headline">#</a></h2>
<p>So what is a ‘responsible’ approach? Generally speaking, responsibility is a <em>‘duty or obligation to take care of something’</em>. Taking responsibility involves actively avoiding that something ‘bad; happens or increasing the probability that something ‘good’ happens. What can be considered ‘right’ or ‘wrong’ is the central question of ethics and has occupied philosophers for many centuries.</p>
<p>As machine learning systems are increasingly deployed in all kinds of applications, several incidents have shown in what ways machine learning systems can have negative consequences. Machine learning models can inherit existing prejudices embedded in society, which can result in discrimination. The increasing complexity of machine learning systems can lead to opaque decision-making systems.</p>
<!-- And the increasing power of the organizations who deploy these systems raises questions about accountability. -->
<p>I have organized these lecture notes along two key moral values: fairness and transparency. Although there exists some overlap, each theme emphasizes a different aspect of a responsible approach to machine learning.</p>
<div class="section" id="fairness">
<h3>Fairness<a class="headerlink" href="#fairness" title="Permalink to this headline">#</a></h3>
<p><a class="reference internal" href="../misc/glossary.html#term-fairness"><span class="xref std std-term">Fairness</span></a> is a moral value that concerns treatment of behavior that is <em>just</em> and <em>free from discrimination</em>. Machine learning models, particularly classifiers, are specifically designed to discriminate between cases. As with any decision-making process, these distinctions can be undesirable from an ethical perspective or unlawful if they disproportionately affect people on the basis of sensitive characteristics such as gender, race, religion, age, and sexual orientation.</p>
<p>In recent years, several incidents have shown that machine learning systems can inherit and amplify social biases embedded in society. In 2016, investigative journalists from Propublica found that COMPAS, a decision support tool for assessing the likelihood of a defendant becoming a recidivist, wrongly labeled African-American defendants as recidivists at much higher rates than white Americans <a class="footnote-reference brackets" href="#footcite-compas2017" id="id1">1</a>. Although concerns regarding the fairness of algorithmic decision-making systems is not new, Propublica’s article sparked an increased interest in the field.</p>
<p>Although math and numbers may seem objective, machine learning models are not value neutral. They are the result of many design choices that embed the values of their developers: which data is collected, what metrics are used to evaluate our models, and which problems do we decide to tackle in the first place? The risk of unfairness is not limited to adversarial actors - even a well-intentioned data scientist has their blind spots.</p>
</div>
<div class="section" id="transparency">
<h3>Transparency<a class="headerlink" href="#transparency" title="Permalink to this headline">#</a></h3>
<p>As a moral value, <a class="reference internal" href="../misc/glossary.html#term-transparency"><span class="xref std std-term">transparency</span></a> can be defined as the <em>degree of openness that allows others to understand what actions are performed</em>. In the context of machine learning, an important dimension of transparency is the extent to which we can understand a model’s prediction-generating process. This is known as <a class="reference internal" href="../misc/glossary.html#term-interpretable-machine-learning"><span class="xref std std-term">interpretable machine learning</span></a> or <a class="reference internal" href="../misc/glossary.html#term-explainable-machine-learning"><span class="xref std std-term">explainable machine learning</span></a>.</p>
<p>In some cases, the best performing models are complex models such as ensembles or deep neural networks. As the complexity of models increases, it generally becomes more difficult for humans to understand their behavior. In many contexts, it can be valuable or even imperative to understand why a machine learning model makes certain predictions. For example, machine learning practitioners might use explanations to understand where the model fails and how it might be improved.</p>
<!-- ### Accountability

Previously, I have defined responsibility as a duty to take care of something. Responsibility can also be defined as being *accountable* for something. {term}`Accountability` considers being held responsible for one’s actions, typically after something 'bad' has happened. Due to the apparent complexity of algorithmic systems, organizations may try to divert blame to the algorithm: *“oh, it’s just the algorithm.”* Algorithmic accountability is the idea that an institution should be held accountable for the use, design, and decisions of an algorithmic system. It involves taking adequate measures to comply with ethical principles or legal regulations, including detailed documentation and clear procedures for appealing decisions.

An important tool for fostering accountability is auditing, in which the development process, usage, and impact of an algorithmic system are closely inspected - either through internal procedures or by an external third party. -->
</div>
</div>
<div class="section" id="for-who-is-this-book">
<h2>For who is this book?<a class="headerlink" href="#for-who-is-this-book" title="Permalink to this headline">#</a></h2>
<p>The intended audience of this book are (undergraduate) computer science students, practitioners, and researchers interested in responsible machine learning. It is expected that you are familiar with machine learning in general and supervised machine learning in particular. This includes the high-level workings of basic classification algorithms, model selection approaches, and evaluation metrics. To get you up to speed, I will go over some of the basic concepts in the chapter <a class="reference internal" href="machinelearning/introduction.html#ml-preliminaries"><span class="std std-ref">Machine Learning Preliminaries</span></a>.</p>
</div>
<div class="section" id="what-is-covered-in-this-book">
<h2>What is covered in this book?<a class="headerlink" href="#what-is-covered-in-this-book" title="Permalink to this headline">#</a></h2>
<p>With the increasing usage of machine learning in real-world applications, we have also seen more examples of how machine learning can go wrong. As a result, the interest in a more responsible approach to computer science has surged. At one end of the spectrum, the field has been productive in generating principles, guidelines, and frameworks for more ‘ethical’ artificial intelligence. However, many of these principles are too broad to guide the daily practice of a data scientist or machine learning engineer. At the other end of the spectrum, many technical solutions have been proposed, which can forego the real-world context of machine learning applications.</p>
<p>In this book, I have tried to balance these extremes by setting out a practical approach that acknowledges the sociotechnical context in which machine learning applications are used.</p>
<p>The techniques, challenges, and considerations discussed in these lecture notes mostly involve applications based on supervised learning. Nonetheless, the sociotechnical approach that is encouraged throughout the lecture notes can be applied to any analytics project.</p>
<p>Of course, there is much more to cover than what reasonably fits into one book. In addition to the values of fairness and explainability, other important requirements are, for example, technical safety, privacy, sustainability. Additionally, there are many adjacent topics such as moral philosophy, accessible product design, and organizational best practices. Although organizational structures, including efforts such as ethics committees and programs for diversity and inclusion, are crucial for operationalizing responsible machine learning these are not the main focus of these lecture notes.</p>
</div>
<div class="section" id="navigating-this-book">
<h2>Navigating this book<a class="headerlink" href="#navigating-this-book" title="Permalink to this headline">#</a></h2>
<p>The rest of this book is organized as follows:</p>
<ul class="simple">
<li><p><a class="reference internal" href="machinelearning/introduction.html#ml-preliminaries"><span class="std std-ref">Machine Learning</span></a> contains a quick recap of relevant machine learning concepts.</p></li>
<li><p><a class="reference internal" href="../fairness/introduction.html#intro-fairness"><span class="std std-ref">Fairness</span></a> dives into the topic of algorithmic fairness, including techniques to discover and mitigate undesirable discrimination that have been proposed in the compute science literature.</p></li>
<li><p><a class="reference internal" href="../explainability/introduction.html#intro-xai"><span class="std std-ref">Explainable Artificial Intelligence</span></a> covers several techniques for creating interpretable models and explaining black-box machine learning models.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Developing machine learning applications is subjective: it will require you to make many decisions, which often involves making trade-offs between competing criteria. I believe that taking responsibility requires one to make these decisions explicit. Given the great variety of norms and values that exist in the world, I would like to acknowledge that some of the ideas discussed in this book may reflect perspectives you do not agree with. The goal of this book is not to enforce a particular moral framework or political point-of-view. Instead, I aim to provide you with the knowledge and tools to identify trade-offs and make substantiated decisions.</p>
<p>This book summarizes many of the things I have learned so far on my journey in the field of responsible machine learning. Nevertheless, I am but a person with my own limited perspective. In particular, I would like to acknowledge that as an able-bodied white women that was born and raised in the Netherlands, I lack lived experience that is the daily reality of many people in marginalized communities. My background is primarily technical and I am still learning from all great scholars in this interdisciplinary field. I hope you will too.</p>
</div>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">#</a></h2>
<div class="docutils container" id="id2">
<dl class="footnote brackets">
<dt class="label" id="footcite-compas2017"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>Julia Angwin and Jeff Larson. Machine Bias. 2016. URL: <a class="reference external" href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing</a>.</p>
</dd>
</dl>
</div>
<hr class="footnotes docutils" />
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./introduction"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../index.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">An Introduction to Responsible Machine Learning</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="machinelearning/introduction.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Machine Learning Preliminaries</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Hilde Weerts<br/>
  
      &copy; Copyright 2023.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>